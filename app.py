import streamlit as st
import pandas as pd
import warnings

# å±è”½éå…³é”®è­¦å‘Š
warnings.filterwarnings("ignore")

# --- UI Extras ---
from streamlit_extras.colored_header import colored_header
from streamlit_extras.metric_cards import style_metric_cards
from streamlit_extras.badges import badge

# --- Core Modules ---
from core.fetcher import PaperFetcher
from core.processor import DataProcessor
from core.llm_engine import LLMSummarizer
from utils.visuals import plot_paper_map

# 1. é¡µé¢åŸºç¡€é…ç½®
st.set_page_config(
    page_title="DeepSurvey",
    layout="wide",
    page_icon="ğŸ”­",
    initial_sidebar_state="expanded"
)

# 2. æ³¨å…¥è‡ªå®šä¹‰ CSS (æç®€ä¸»ä¹‰è®¾è®¡)
st.markdown("""
<style>
    /* å…¨å±€å­—ä½“ */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
    html, body, [class*="css"] {
        font-family: 'Inter', sans-serif;
    }

    /* éšè— Streamlit é»˜è®¤èœå•å’Œ Footer */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}

    /* è°ƒæ•´é¡¶éƒ¨ç•™ç™½ */
    .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }

    /* æœç´¢æ¡†ç¾åŒ– */
    .stTextInput > div > div > input {
        font-size: 1.2rem;
        border-radius: 10px;
        padding: 10px;
    }

    /* ä¾§è¾¹æ ç¾åŒ– */
    [data-testid="stSidebar"] {
        background-color: #f8f9fa;
        border-right: 1px solid #e9ecef;
    }

    /* æŒ‰é’®ç¾åŒ– */
    .stButton > button {
        border-radius: 8px;
        font-weight: 600;
        width: 100%;
    }
</style>
""", unsafe_allow_html=True)

# ==========================================
# Sidebar: é…ç½®ä¸­å¿ƒ
# ==========================================
with st.sidebar:
    st.markdown("## Configuration")

    st.divider()

    st.markdown("#### Semantic Scholar")
    s2_api_key = st.text_input("API Key", type="password", help="Optional but recommended for speed.")

    st.divider()

    st.markdown("#### Embedding Strategy")
    embed_mode = st.radio(
        "Source",
        ["S2 Embeddings (Fast)", "Local Embeddings (Deep)"],
        label_visibility="collapsed",
        captions=[
            "Uses API vectors. Fast, but may miss papers.",
            "Computes locally. Slower, but 100% coverage."
        ]
    )
    mode_key = 's2' if "S2" in embed_mode else 'local'

    st.divider()

    st.markdown("#### LLM Intelligence")
    llm_provider = st.selectbox("Provider", ["openai", "openai-compatible", "anthropic", "gemini", "azure"])
    llm_key = st.text_input("API Key", type="password")

    llm_base_url = None
    if llm_provider == "openai-compatible":
        llm_base_url = st.text_input("Base URL", placeholder="https://api.deepseek.com")

    llm_model = st.text_input("Model Name", value="gpt-3.5-turbo")

    st.markdown("---")
    badge(type="github", name="streamlit/streamlit", url="https://github.com/streamlit/streamlit")
    st.caption("v1.0.0 | AI Innovation Contest")

# ==========================================
# Main: ä¸»ç•Œé¢
# ==========================================

# Hero Section
colored_header(
    label="DeepSurvey: AI Domain Explorer",
    description="Visualize research trends, discover hidden clusters, and generate insights in seconds.",
    color_name="violet-70"
)

# æœç´¢ä¸æ“ä½œåŒº
col_search, col_btn = st.columns([4, 1])
with col_search:
    query = st.text_input(
        "Search Topic",
        placeholder="e.g. 'Large Language Models' or 'Quantum Error Correction'...",
        label_visibility="collapsed"
    )

with col_btn:
    # ä¸ºäº†å¯¹é½è¾“å…¥æ¡†ï¼ŒåŠ ä¸ªç©ºè¡Œ
    # st.write("")
    # st.write("")
    analyze_btn = st.button("ğŸš€ Analyze", type="primary")

# Session State åˆå§‹åŒ–
if 'data' not in st.session_state:
    st.session_state.data = None

# --- æ ¸å¿ƒé€»è¾‘æ‰§è¡Œ ---
if query and analyze_btn:
    # ä½¿ç”¨ Status å®¹å™¨æ›¿ä»£ Spinnerï¼Œçœ‹èµ·æ¥æ›´é«˜çº§
    with st.status(f"ğŸ•µï¸â€â™‚ï¸ Scouting knowledge graph for: **{query}**", expanded=True) as status:

        # 1. Fetch
        st.write("ğŸ“¡ Connecting to Semantic Scholar Graph...")
        fetcher = PaperFetcher(api_key=s2_api_key if s2_api_key else None)
        papers = fetcher.search_papers(query, limit=100)

        if not papers:
            status.update(label="No papers found!", state="error", expanded=False)
            st.error("No papers found. Try a broader keyword.")
        else:
            st.write(f"ğŸ“¦ Retrieved {len(papers)} unique papers. Processing embeddings...")
            df = pd.DataFrame(papers)

            # 2. Process
            processor = DataProcessor()
            df_processed = processor.process_data(df, embedding_mode=mode_key)

            if df_processed.empty:
                status.update(label="Data Error", state="error")
                st.error("All papers dropped. Try 'Local Embeddings'.")
            else:
                st.write("ğŸ§  Performing HDBSCAN clustering & UMAP projection...")

                # 3. LLM
                if llm_key:
                    st.write("ğŸ¤– Invoking LLM for topic summarization...")
                    summarizer = LLMSummarizer(api_key=llm_key, model_name=llm_model, base_url=llm_base_url)
                    cluster_labels = summarizer.summarize_clusters(df_processed)
                else:
                    st.warning("Skipping LLM summary (No Key). Using generic labels.")
                    cluster_labels = {i: f"Cluster {i}" for i in df_processed['cluster'].unique()}
                    if -1 in cluster_labels: cluster_labels[-1] = "Outliers"

                st.session_state.data = (df_processed, cluster_labels)
                status.update(label="Analysis Complete!", state="complete", expanded=False)

# ==========================================
# Visualization: ç»“æœå±•ç¤º
# ==========================================
if st.session_state.data:
    raw_df, labels = st.session_state.data

    st.divider()

    # 1. ä»ªè¡¨ç›˜ç»Ÿè®¡å¡ç‰‡ (Metric Cards)
    m1, m2, m3, m4 = st.columns(4)
    num_clusters = len([k for k in labels.keys() if k != -1])

    m1.metric(label="Papers Analyzed", value=len(raw_df))
    m2.metric(label="Topics Identified", value=num_clusters)
    m3.metric(label="Avg. Citations", value=int(raw_df['citations'].mean()))
    m4.metric(label="Time Span", value=f"{raw_df['year'].min()} - {raw_df['year'].max()}")

    # ç¾åŒ–å¡ç‰‡æ ·å¼
    style_metric_cards(border_left_color="#764ba2", box_shadow=True)

    # 2. äº¤äº’å¼ç­›é€‰åŒº
    st.write("")
    with st.expander("ğŸŒªï¸ **Filter & Explore Control Panel**", expanded=True):
        df_display = raw_df.copy()
        df_display['topic_name'] = df_display['cluster'].map(labels)

        f1, f2, f3 = st.columns(3)
        with f1:
            all_topics = sorted(list(labels.values()))
            selected_topics = st.multiselect("Select Topics", options=all_topics, default=all_topics)
        with f2:
            max_cite = int(df_display['citations'].max())
            min_cite_val = int(df_display['citations'].min())
            min_cite = st.slider("Min Citations", min_cite_val, max_cite,
                                 min_cite_val) if max_cite > min_cite_val else min_cite_val
        with f3:
            min_y, max_y = int(df_display['year'].min()), int(df_display['year'].max())
            sel_years = st.slider("Time Period", min_y, max_y, (min_y, max_y)) if max_y > min_y else (min_y, max_y)

        # ç­›é€‰é€»è¾‘
        mask = (
                (df_display['topic_name'].isin(selected_topics)) &
                (df_display['citations'] >= min_cite) &
                (df_display['year'] >= sel_years[0]) &
                (df_display['year'] <= sel_years[1])
        )
        df_filtered = df_display[mask]

    # 3. å¯è§†åŒ–å›¾è¡¨
    if not df_filtered.empty:
        st.subheader("ğŸ—ºï¸ Knowledge Landscape")

        # ä¿®å¤ Warning çš„å…³é”®ç‚¹: ä½¿ç”¨ width="stretch" è€Œä¸æ˜¯ use_container_width
        st.plotly_chart(
            plot_paper_map(df_filtered, labels),
            width="stretch"  # <--- ä¿®å¤å¤„
        )
    else:
        st.warning("No papers match your current filters.")

    # 4. æ•°æ®è¯¦æƒ…
    st.subheader("ğŸ“„ Paper Details")
    st.dataframe(
        df_filtered[['title', 'topic_name', 'venue', 'year', 'citations', 'url']],
        column_config={
            "url": st.column_config.LinkColumn("Link"),
            "citations": st.column_config.ProgressColumn("Impact", format="%d", min_value=0, max_value=max_cite)
        },
        use_container_width=True  # Dataframe è¿™é‡Œçš„å‚æ•°æš‚æ—¶è¿˜æ²¡è¿‡æœŸï¼Œæˆ–è€…ä¹Ÿå¯ä»¥ä¸åŠ 
    )