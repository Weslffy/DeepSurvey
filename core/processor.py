import numpy as np
import pandas as pd
from umap import UMAP
import hdbscan
from sentence_transformers import SentenceTransformer


class DataProcessor:
    def __init__(self):
        self.local_model = None

    def _load_local_model(self):
        if self.local_model is None:
            print("ğŸ”„ Loading local embedding model (all-MiniLM-L6-v2)...")
            self.local_model = SentenceTransformer('all-MiniLM-L6-v2')

    def process_data(self, df, embedding_mode='s2'):
        if df.empty: return df

        # --- 1. Embedding å¤„ç† ---
        if embedding_mode == 's2':
            valid_mask = df['embedding'].apply(lambda x: isinstance(x, list) and len(x) > 0)
            if not valid_mask.all():
                print(f"âš ï¸ S2 Mode: Dropping {(~valid_mask).sum()} papers without embeddings.")
                df = df[valid_mask].copy()
            if df.empty: return df
            matrix = np.stack(df['embedding'].values)
        else:
            print(f"ğŸ§® Local Mode: Computing embeddings for {len(df)} papers...")
            self._load_local_model()
            texts = (df['title'].fillna("") + ". " + df['abstract'].fillna("")).tolist()
            matrix = self.local_model.encode(texts, show_progress_bar=True)
            df['embedding'] = list(matrix)

        # å‚æ•°è®¾ç½®
        n_samples = len(matrix)
        n_neighbors = min(15, n_samples - 1)
        if n_neighbors < 2: n_neighbors = 2

        # --- 2. èšç±»ä¸“ç”¨ UMAP (é™ç»´åˆ° 10 ç»´) ---
        # 10ç»´è¶³å¤Ÿä¿ç•™å¤æ‚æ‹“æ‰‘ç»“æ„ï¼Œè®© HDBSCAN æ›´å¥½å·¥ä½œ
        print(f"ğŸš€ Step A: Reducing to 10D for Clustering (Input: {matrix.shape})...")
        umap_cluster = UMAP(
            n_neighbors=n_neighbors,
            n_components=10,  # å…³é”®ä¿®æ”¹ï¼šä¿ç•™æ›´å¤šä¿¡æ¯
            min_dist=0.0,
            metric='cosine',
            random_state=42
        )
        embed_cluster = umap_cluster.fit_transform(matrix)

        # --- 3. HDBSCAN èšç±» ---
        print("ğŸ§© Step B: Running HDBSCAN...")
        # min_samples è®¾å°ä¸€ç‚¹ï¼Œå¯ä»¥å‡å°‘è¢«å½’ä¸ºå™ªéŸ³(-1)çš„ç‚¹
        clusterer = hdbscan.HDBSCAN(
            min_cluster_size=17,
            min_samples=2,  # å…³é”®ä¿®æ”¹ï¼šé™ä½å™ªéŸ³å®¹å¿åº¦ï¼Œè®©æ›´å¤šç‚¹å½’ç±»
            metric='euclidean',
            gen_min_span_tree=True
        )
        cluster_labels = clusterer.fit_predict(embed_cluster)
        df['cluster'] = cluster_labels

        noise_count = (cluster_labels == -1).sum()
        n_clusters = len(set(cluster_labels)) - (1 if noise_count > 0 else 0)
        print(f"âœ… Found {n_clusters} clusters. Noise points: {noise_count}/{n_samples}")

        # --- 4. å¯è§†åŒ–ä¸“ç”¨ UMAP (é™ç»´åˆ° 2 ç»´) ---
        print("ğŸ¨ Step C: Reducing to 2D for Visualization...")
        umap_vis = UMAP(
            n_neighbors=n_neighbors,
            n_components=2,
            min_dist=0.1,  # ç¨å¾®åˆ†å¼€ä¸€ç‚¹ï¼Œå¥½çœ‹
            metric='cosine',
            random_state=42
        )
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ç”¨åŸå§‹çŸ©é˜µå†è·‘ä¸€æ¬¡ UMAP åˆ° 2Dï¼Œé€šå¸¸æ¯” 10D->2D æ•ˆæœæ›´è‡ªç„¶
        projections = umap_vis.fit_transform(matrix)

        df['x'] = projections[:, 0]
        df['y'] = projections[:, 1]

        return df